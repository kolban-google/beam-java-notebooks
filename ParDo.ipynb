{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb7f722",
   "metadata": {},
   "source": [
    "# Apache Beam - ParDo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a283caf",
   "metadata": {},
   "source": [
    "The `ParDo` allows us to execute code element by element on a `PCollection`.  At the highest level, think of `ParDo` as no more than another `PTransform`.  This means that we can use a `ParDo` as a pipline step:\n",
    "\n",
    "```\n",
    "PCollection myPcollection = ...;\n",
    "myPcollection.apply(\"Perform Pardo\", ParDo.of(...));\n",
    "```\n",
    "\n",
    "When we create an instance of a `ParDo`, we need to pass in a class that extends `DoFn`.  We pass in the instance using the `.of()` method.  This class contains a method called `processElement` that is called *once* for each element found in the `PCollection`.  During execution, the `processElement` method will add zero, one or more elements into an output `PCollection` which will be the output `PCollection` of the `ParDo` transform itself.\n",
    "\n",
    "The `processElement` method is likely to have a signature of:\n",
    "\n",
    "```\n",
    "@ProcessElement\n",
    "public void processElement(@Element inputT element, OutputReceiver<outputT> out) {\n",
    "  ... code here\n",
    "}\n",
    "```\n",
    "\n",
    "Each element in the input PCollection is passed into the method through the `element` parameter.  The `OutputReceiver` parameter has a method on it called `output` that allows us to propagate an output value.\n",
    "\n",
    "![Beam%20-%20Page%202.png](attachment:Beam%20-%20Page%202.png)\n",
    "\n",
    "\n",
    "* [JavaDoc: Class ParDo](https://beam.apache.org/releases/javadoc/2.42.0/org/apache/beam/sdk/transforms/ParDo.html)\n",
    "* [JavaDoc: Class DoFn](https://beam.apache.org/releases/javadoc/2.42.0/index.html?org/apache/beam/sdk/transforms/DoFn.html)\n",
    "\n",
    "First, we define the dependencies that we wish to load from the Maven repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38402951",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "\n",
    "<dependency>\n",
    "  <groupId>org.apache.beam</groupId>\n",
    "  <artifactId>beam-sdks-java-core</artifactId>\n",
    "  <version>2.40.0</version>\n",
    "</dependency>\n",
    "\n",
    "<dependency>\n",
    "  <groupId>org.apache.beam</groupId>\n",
    "  <artifactId>beam-runners-direct-java</artifactId>\n",
    "  <version>2.40.0</version>\n",
    "  <scope>runtime</scope>\n",
    "</dependency>\n",
    "\n",
    "<dependency>\n",
    "  <groupId>org.slf4j</groupId>\n",
    "  <artifactId>slf4j-jdk14</artifactId>\n",
    "  <version>2.0.6</version>\n",
    "</dependency>\n",
    "\n",
    "<dependency>\n",
    "  <groupId>org.slf4j</groupId>\n",
    "  <artifactId>slf4j-api</artifactId>\n",
    "  <version>2.0.6</version>\n",
    "</dependency>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6211db4d",
   "metadata": {},
   "source": [
    "Next we define our imports required for execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a00821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.util.Arrays;\n",
    "import java.util.List;\n",
    "\n",
    "import org.apache.beam.sdk.Pipeline;\n",
    "import org.apache.beam.sdk.options.Default;\n",
    "import org.apache.beam.sdk.options.Description;\n",
    "import org.apache.beam.sdk.options.PipelineOptionsFactory;\n",
    "import org.apache.beam.sdk.options.PipelineOptions;\n",
    "import org.apache.beam.sdk.options.StreamingOptions;\n",
    "import org.apache.beam.sdk.transforms.Create;\n",
    "import org.apache.beam.sdk.values.PCollection;\n",
    "import org.apache.beam.sdk.transforms.DoFn;\n",
    "import org.apache.beam.sdk.transforms.ParDo;\n",
    "import org.apache.beam.sdk.transforms.ProcessFunction;\n",
    "import org.apache.beam.sdk.transforms.MapElements;\n",
    "import org.apache.beam.sdk.values.TypeDescriptors;\n",
    "import org.apache.beam.sdk.values.PCollectionView;\n",
    "import org.apache.beam.sdk.transforms.View;\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "import java.util.logging.Level;\n",
    "\n",
    "String args[] = new String[] {};\n",
    "var options = PipelineOptionsFactory.fromArgs(args).withValidation().create();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ed5b0",
   "metadata": {},
   "source": [
    "Now we define our `DoFn` that is going to be executed once per element.  In this example, we simply write the output to the output stream (console)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09e88661",
   "metadata": {},
   "outputs": [],
   "source": [
    "public class LoggingDoFn<T> extends DoFn<T, T>  {\n",
    "  @ProcessElement\n",
    "  public void processElement(@Element T element, OutputReceiver<T> out) {\n",
    "    System.out.println(element);\n",
    "    out.output(element);\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad43a0b9",
   "metadata": {},
   "source": [
    "Finally, we run the pipeline and see the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "843fa5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World!\n",
      "Hello!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DONE"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var pipeline = Pipeline.create(options);\n",
    "pipeline\n",
    "  .apply(\"Create elements\", Create.of(Arrays.asList(\"Hello!\", \"World!\")))\n",
    "  .apply(\"Print elements\",ParDo.of(new LoggingDoFn<>()));\n",
    "pipeline.run().waitUntilFinish();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e31a293",
   "metadata": {},
   "source": [
    "## DoFn Lifecycle methods\n",
    "The DoFn class associated with the ParDo will always have a processElement method.  It is the processElement method that is called once per element in the input PCollection.  However, there are other lifecycle methods.\n",
    "\n",
    "We can further annotate a `DoFn` class with other lifecycle methods including:\n",
    "\n",
    "* `@Setup` - Called once when the DoFn is initialized.\n",
    "* `@StartBundle` - Called a the start of each bundle processed.\n",
    "* `@FinishBundle` - Called when a bundle has been processed.\n",
    "* `@Teardown` - Called when the work has finished (opposite of @Setup).\n",
    "\n",
    "\n",
    "We will find that the `@Setup` is called first, next `@StartBundle`, next `@ProcessElement`, next `@FinishBundle`.  We may loop around `@StartBundle`, `@ProcessElement`, `@FinishBundle` before finally calling `@Teardown`.\n",
    "\n",
    "It is important to realize that a `DoFn` instance may be reused when it has completed previous work.  As such, don't assume *default* state when it is created.  Set state in `@Setup` and `@StartBundle` as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f47d2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup called! ThreadId: 27, ClassInstance: 80956611\n",
      "Setup called! ThreadId: 25, ClassInstance: 1680334854\n",
      "StartBundle called! ThreadId: 25, ClassInstance: 1680334854\n",
      "Hello!\n",
      "finishBundle called! ThreadId: 25, ClassInstance: 1680334854\n",
      "StartBundle called! ThreadId: 27, ClassInstance: 80956611\n",
      "World!\n",
      "finishBundle called! ThreadId: 27, ClassInstance: 80956611\n",
      "Teardown called! ThreadId: 29, ClassInstance: 1680334854\n",
      "Teardown called! ThreadId: 29, ClassInstance: 80956611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DONE"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public class MyParDoFn extends DoFn<String, String> {\n",
    "\n",
    "  private void logPipelineOptions(PipelineOptions options) {\n",
    "    System.out.println(\"- jobName: \" + options.getJobName());\n",
    "    System.out.println(\"- optionsId: \" + options.getOptionsId());      \n",
    "  }\n",
    "    \n",
    "  // Setup function has no arguments\n",
    "  @Setup\n",
    "  public void setup() {\n",
    "    System.out.println(\"Setup called! ThreadId: \" +\n",
    "      Thread.currentThread().getId() + \", ClassInstance: \" + System.identityHashCode(this));\n",
    "  }\n",
    "  \n",
    "  // Start Bundle has optional arguments of:\n",
    "  // - StartBundleContext\n",
    "  // - PipelineOptions\n",
    "  // - BundleFinalizer\n",
    "  @StartBundle\n",
    "  public void startBundle(\n",
    "    DoFn<String, String>.StartBundleContext context,\n",
    "    PipelineOptions options) {\n",
    "    System.out.println(\"StartBundle called! ThreadId: \" +\n",
    "      Thread.currentThread().getId() + \", ClassInstance: \" + System.identityHashCode(this));\n",
    "    //logPipelineOptions(options);      \n",
    "  }\n",
    "    \n",
    "  @FinishBundle\n",
    "  public void finishBundle() {\n",
    "    System.out.println(\"finishBundle called! ThreadId: \" +\n",
    "      Thread.currentThread().getId() + \", ClassInstance: \" + System.identityHashCode(this));\n",
    "  }\n",
    "  \n",
    "  @Teardown\n",
    "  public void teardown() {\n",
    "    System.out.println(\"Teardown called! ThreadId: \" +\n",
    "      Thread.currentThread().getId() + \", ClassInstance: \" + System.identityHashCode(this));\n",
    "  }\n",
    "  \n",
    "  @ProcessElement\n",
    "  public void processElement(@Element String word, OutputReceiver<String> out) {\n",
    "    System.out.println(word);\n",
    "    out.output(word);\n",
    "  }\n",
    "}\n",
    "\n",
    "pipeline = Pipeline.create(options);\n",
    "pipeline\n",
    "  .apply(\"Create elements\", Create.of(Arrays.asList(\"Hello!\", \"World!\")))\n",
    "  .apply(\"Print elements\",ParDo.of(new MyParDoFn()));\n",
    "pipeline.run().waitUntilFinish();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611ca94b",
   "metadata": {},
   "source": [
    "## MapElements\n",
    "Similar to `ParDo`, there is a transform called [MapElements](https://beam.apache.org/releases/javadoc/2.42.0/org/apache/beam/sdk/transforms/MapElements.html).  `MapElements` has fewer options than `ParDo` but may be simpler to use.  The general format of MapElements is:\n",
    "\n",
    "```\n",
    "MapElement\n",
    "  .into(... The type of output PCollection)\n",
    "  .via(... how to map the input element to the output element)\n",
    "```\n",
    "\n",
    "The `.into()` takes a `TypeDescriptor` that describes the type.  We can construct our own `TypeDescriptor` or use the helper class called `TypeDescriptors` that knows how to describe common types.\n",
    "\n",
    "We can create a [ProcessFunction](https://beam.apache.org/releases/javadoc/2.42.0/org/apache/beam/sdk/transforms/ProcessFunction.html) that takes an input element and returns an output element.\n",
    "\n",
    "See also:\n",
    "* [JavaDoc: Class TypeDescriptor](https://beam.apache.org/releases/javadoc/2.43.0/org/apache/beam/sdk/values/TypeDescriptor.html)\n",
    "* [JavaDoc: Class TypeDescriptors](https://beam.apache.org/releases/javadoc/2.43.0/org/apache/beam/sdk/values/TypeDescriptors.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "761d9a09",
   "metadata": {},
   "outputs": [
    {
     "ename": "CompilationException",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m\u001b[0m\u001b[1m\u001b[30m\u001b[41mpipeline\u001b[0m\u001b[1m\u001b[30m = Pipeline.create(options);\u001b[0m",
      "\u001b[1m\u001b[31mcannot find symbol\u001b[0m",
      "\u001b[1m\u001b[31m  symbol:   variable pipeline\u001b[0m",
      "",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30mpipeline = Pipeline.create(\u001b[0m\u001b[1m\u001b[30m\u001b[41moptions\u001b[0m\u001b[1m\u001b[30m);\u001b[0m",
      "\u001b[1m\u001b[31mcannot find symbol\u001b[0m",
      "\u001b[1m\u001b[31m  symbol:   variable options\u001b[0m",
      "",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30mpipeline = \u001b[0m\u001b[1m\u001b[30m\u001b[41mPipeline\u001b[0m\u001b[1m\u001b[30m.create(options);\u001b[0m",
      "\u001b[1m\u001b[31mcannot find symbol\u001b[0m",
      "\u001b[1m\u001b[31m  symbol:   variable Pipeline\u001b[0m",
      ""
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline.create(options);\n",
    "pipeline\n",
    "  .apply(\"Create elements\", Create.of(Arrays.asList(\"Hello!\", \"World!\")))\n",
    "  .apply(\"Upper case \", MapElements.into(TypeDescriptors.strings()).via(new ProcessFunction<String, String>() {\n",
    "    public String apply(String text) throws Exception{\n",
    "      return text.toUpperCase();\n",
    "    }\n",
    "  }))\n",
    "  .apply(\"Print elements\",ParDo.of(new LoggingDoFn<>()));\n",
    "pipeline.run().waitUntilFinish();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af099e01",
   "metadata": {},
   "source": [
    "Using the `ProcessFunction`, we can go one step further (if desired) and use a lambda function.  Whether this is more or less readable is going to be matter of taste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b12c70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORLD!\n",
      "HELLO!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DONE"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline.create(options);\n",
    "pipeline\n",
    "  .apply(\"Create elements\", Create.of(Arrays.asList(\"Hello!\", \"World!\")))\n",
    "  .apply(\"Upper case \", MapElements\n",
    "    .into(TypeDescriptors.strings())\n",
    "    .via((String word)->word.toUpperCase()))\n",
    "  .apply(\"Print elements\",ParDo.of(new LoggingDoFn<>()));\n",
    "pipeline.run().waitUntilFinish();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d017c1c2",
   "metadata": {},
   "source": [
    "## Logging in your DoFn\n",
    "Since a ParDo involves writing custom code, you might wish to consider adding log statements to aid in diagnostics.  Beam uses [SLF4J](https://www.slf4j.org/) as its logging interafce.  Since this is wrapper around another log provider, you will want to also specify which back-end logger to use.  I use `java.util.logging` which meant include the `slf4j-jdk14` JAR.\n",
    "\n",
    "Getting SLF4J can JUL working can be a little tricky.  One working solution is to create a file called `jul-log.properties` which contains:\n",
    "\n",
    "```\n",
    "handlers= java.util.logging.ConsoleHandler\n",
    ".level= FINEST\n",
    "java.util.logging.ConsoleHandler.level = FINEST\n",
    "java.util.logging.ConsoleHandler.formatter = java.util.logging.SimpleFormatter\n",
    "java.util.logging.SimpleFormatter.format=[%1$tF %1$tT] [%4$s] [%3$s] %5$s %n\n",
    "```\n",
    "\n",
    "and then modifying the kernel.json file for IJava to include:\n",
    "\n",
    "```\n",
    "\"-Djava.util.logging.config.file=/<path>/jul-log.properties\",        \n",
    "```\n",
    "\n",
    "and restart the kernels.  The output will now show where you launched jupyter.\n",
    "\n",
    "See also:\n",
    "* [Docs: Work with pipeline logs](https://cloud.google.com/dataflow/docs/guides/logging)\n",
    "* [JavaDoc: org.slf4j.LoggerFactory](https://www.slf4j.org/api/org/slf4j/LoggerFactory.html)\n",
    "* [JavaDoc: org.slf4j.Logger](https://www.slf4j.org/api/org/slf4j/Logger.html)\n",
    "* [Java Logging Overview](https://docs.oracle.com/javase/8/docs/technotes/guides/logging/overview.html)\n",
    "* [Java Logging API - Tutorial](https://www.vogella.com/tutorials/Logging/article.html)\n",
    "* java.util.logging.config.file - property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42c74f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World!\n",
      "Hello!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DONE"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final Logger LOG = LoggerFactory.getLogger(\"test\");\n",
    "\n",
    "public class LoggingDoFn<T> extends DoFn<T, T>  {\n",
    "  @ProcessElement\n",
    "  public void processElement(@Element T element, OutputReceiver<T> out) {\n",
    "    System.out.println(element);\n",
    "    LOG.debug(\"debug: \" + element);\n",
    "    LOG.trace(\"trace: \" + element);\n",
    "    LOG.info(\"info: \" + element);\n",
    "    out.output(element);\n",
    "  }\n",
    "} // End of LoggingDoFn\n",
    "\n",
    "var pipeline = Pipeline.create(options);\n",
    "pipeline\n",
    "  .apply(\"Create elements\", Create.of(Arrays.asList(\"Hello!\", \"World!\")))\n",
    "  .apply(\"Print elements\",ParDo.of(new LoggingDoFn<>()));\n",
    "pipeline.run().waitUntilFinish();\n",
    "System.out.println(\"Note: Look to where you launched Jupyter to see the log output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02adf77",
   "metadata": {},
   "source": [
    "## Side Inputs\n",
    "Consider a `DoFn` processing an input `PCollection`.  It is presented with each element in the `PCollection` one element at a time.  A side input is an additional `PCollection` that is also made available to the `DoFn` when processing an element.  The side input is immutable and is seen by all invocations of the `processElement()` function.\n",
    "\n",
    "To pass in a side input, we add additional options to the construction of our `ParDo` transform:\n",
    "\n",
    "```\n",
    "ParDo.of(new MyDoFn()).withSideInputs(PCollectionView<?> myView)\n",
    "```\n",
    "\n",
    "Note that the side input being passed in is a `PCollectionView` and **not** a `PCollection`.  To create a `PCollectionView`, we use the `View` transform.  The `View` transform takes as input a `PCollection` and returns a `PCollectionView`.\n",
    "\n",
    "```\n",
    "PCollectionView<viewT> = pipeline.apply(View.asList());\n",
    "```\n",
    "\n",
    "So what *is* a `PCollectionView`?  Think of it as a container for a single value where that single value can be one of:\n",
    "\n",
    "* a single value - `View.asSingleton`\n",
    "* an interrable - `View.asIterable`\n",
    "* a list - `View.asList`\n",
    "* a map - `View.asMap`\n",
    "* a multimap - `View.asMultimap`\n",
    "\n",
    "Putting it another way, the `PCollectionView` contains a single value where that value may be a singleton, an iterrable, a list, a map or a multimap.\n",
    "\n",
    "When the `ProcessElement` method of the `DoFn` is called, it is passed a parameter called `ProcessContext`.  Within `ProcessContext` is a method called `sideInput`.  It has the signature:\n",
    "\n",
    "```\n",
    "<T> sideInput(PCollectionView<T> view)\n",
    "```\n",
    "\n",
    "What this means is that it returns the value passed into the `ParDo` using the `withSideInputs()` method.\n",
    "\n",
    "When we read how side inputs are supposed to be used, we seem to get into a loop.  Let me explain.\n",
    "\n",
    "We use side inputs in the context of a `ParDo`.  A `ParDo` is a `PTransform`.  We invoke a `PTransform` using `apply` on a `PCollection`.  When we create a `ParDo`, we also pass a reference to a `DoFn` that is executed for each element.\n",
    "\n",
    "In code this might be:\n",
    "\n",
    "```\n",
    "PCollection pc = pCollectionStart\n",
    "  .apply(ParDo.of(new MyDoFn()));\n",
    "```\n",
    "\n",
    "Now if we wish to pass in a side input, we add `withSideInputs` passing in a `PCollectionView`.\n",
    "```\n",
    "PCollectionView<T> myPCollectionView = ... create the PCollectionView;\n",
    "PCollection pc = pCollectionStart\n",
    "  .apply(ParDo.of(new MyDoFn()).withSideInputs(myPCollectionView);\n",
    "```\n",
    "\n",
    "hopefully, so far so good.  Now let us look at the `DoFn` that is invoked.  It has a `processElement` method that may look like:\n",
    "\n",
    "```\n",
    "@ProcessElement\n",
    "public void processElement(ProcessContext context) {\n",
    "  ... Do Work here ...\n",
    "}\n",
    "```\n",
    "\n",
    "again, so far so good.  Now comes the puzzle.  The way we get the side input within `processElement` is by calling  `context.sideInput()` ... however, when we look at that method, it expects a PCollectionView as input.  This needs to be the *same* `PCollectionView` that was passed into the `withSideInputs()` on the `ParDo`.  This is starting to get complicated.  The best I have found is to add a private member to my `DoFn` class that is a `PCollectionView` that is passed in when the `DoFn` is created.\n",
    "\n",
    "```\n",
    "public class MyDoFN<T> extends DoFn<T, T>  {\n",
    "  private PCollectionView<Q> view;\n",
    "  \n",
    "  public GreetingsDoFn(PCollectionView<List<String>> view) {\n",
    "    this.view = view;\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "This then allows me to refer to the `PCollectionView` in my `processElement` when I wish to receive the side input.\n",
    "\n",
    "Can we do multiple side inputs?\n",
    "\n",
    "See also:\n",
    "* [Beam Programming Guide - Side Inputs](https://beam.apache.org/documentation/programming-guide/#side-inputs)\n",
    "* [Side Input Patterns](https://beam.apache.org/documentation/patterns/side-inputs/)\n",
    "* [JavaDoc: PCollectionView](https://beam.apache.org/releases/javadoc/2.43.0/org/apache/beam/sdk/values/PCollectionView.html)\n",
    "* [JavaDoc: View](https://beam.apache.org/releases/javadoc/2.43.0/org/apache/beam/sdk/transforms/View.html)\n",
    "* [JavaDoc: DoFn.ProcessContext](https://beam.apache.org/releases/javadoc/2.43.0/org/apache/beam/sdk/transforms/DoFn.ProcessContext.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65f9a5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Good to see you, Hello, Welcome]\n",
      "Good to see you, Neil\n",
      "Hello, Neil\n",
      "Welcome, Neil\n",
      "[Good to see you, Hello, Welcome]\n",
      "Good to see you, John\n",
      "Hello, John\n",
      "Welcome, John\n",
      "Neil\n",
      "John\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DONE"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public class GreetingsDoFn<String> extends DoFn<String, String>  {\n",
    "  private PCollectionView<List<String>> view;\n",
    "  \n",
    "  public GreetingsDoFn(PCollectionView<List<String>> view) {\n",
    "    this.view = view;\n",
    "  }\n",
    "  @ProcessElement\n",
    "  public void processElement(@Element String element, OutputReceiver<String> out, ProcessContext context) {\n",
    "    System.out.println(context.sideInput(view));\n",
    "    List<String> greetings = context.sideInput(view);\n",
    "    for (String greeting: greetings) {\n",
    "      System.out.println(greeting + \", \" + element);\n",
    "    }\n",
    "    out.output(element);\n",
    "  }\n",
    "}\n",
    "\n",
    "List<String> greetings = Arrays.asList(\"Hello\", \"Welcome\", \"Good to see you\");\n",
    "\n",
    "var pipeline = Pipeline.create(options);\n",
    "PCollectionView<List<String>> sideInputData = pipeline\n",
    "  .apply(\"Make input\", Create.of(greetings))\n",
    "  .apply(\"View\", View.<String>asList());\n",
    "pipeline\n",
    "  .apply(\"Create elements\", Create.of(Arrays.asList(\"Neil\", \"John\")))\n",
    "  .apply(\"Greetings\",ParDo.of(new GreetingsDoFn<>(sideInputData)).withSideInputs(sideInputData))\n",
    "  .apply(\"Print elements\",ParDo.of(new LoggingDoFn<>()));\n",
    "pipeline.run().waitUntilFinish();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32d6766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "11.0.16+8-post-Debian-1deb10u1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
